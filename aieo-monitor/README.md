# AI Citation Monitor

> Track whether AI models cite paintballevents.net when answering paintball-related queries

## ğŸ¯ Purpose

This monitoring system tracks citation rates across multiple AI models (OpenAI, Claude, DeepSeek, Grok, Perplexity, Llama) to understand:
- Which AI platforms find and cite paintballevents.net
- How citation rates change over time
- Which query phrasings work best
- Competitor visibility in AI search results

## ğŸ—ï¸ Architecture

**GitHub Actions** (Weekly Cron) â†’ **MySQL on Bluehost** â†’ **PHP Dashboard**

- âœ… No Python hosting needed on Bluehost
- âœ… Free GitHub Actions (2,000 minutes/month)
- âœ… Scalable to multiple models
- âœ… Clean separation of concerns

## ğŸš€ Quick Start

See [SETUP.md](SETUP.md) for detailed setup instructions.

**TL;DR:**
1. Create MySQL database on Bluehost
2. Run `database/schema.sql` 
3. Add secrets to GitHub repository
4. Upload `monitor.php` to Bluehost
5. Done! Runs automatically every Monday.

## ğŸ“ Project Structure

```
aieo-monitor/
â”œâ”€â”€ config/               # Configuration files
â”‚   â””â”€â”€ queries.json      # Test queries
â”œâ”€â”€ models/               # AI model implementations
â”‚   â”œâ”€â”€ base_model.py     # Abstract base class
â”‚   â”œâ”€â”€ openai_model.py   # OpenAI GPT-4o âœ“
â”‚   â”œâ”€â”€ claude_model.py   # Anthropic Claude âœ“
â”‚   â”œâ”€â”€ deepseek_model.py # DeepSeek (stub)
â”‚   â”œâ”€â”€ grok_model.py     # Grok (stub)
â”‚   â”œâ”€â”€ perplexity_model.py # Perplexity (stub)
â”‚   â””â”€â”€ llama_model.py    # Llama (stub)
â”œâ”€â”€ database/             # Database layer
â”‚   â”œâ”€â”€ schema.sql        # MySQL schema
â”‚   â””â”€â”€ operations.py     # CRUD operations
â”œâ”€â”€ run_monitor.py        # Main orchestrator
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ monitor.php           # Web dashboard
â””â”€â”€ SETUP.md             # Setup instructions
```

## ğŸ¤– Supported Models

| Model | Status | Provider |
|-------|--------|----------|
| GPT-4o | âœ… Active | OpenAI |
| Claude 3.7 Sonnet | âœ… Active | Anthropic |
| DeepSeek Chat | ğŸš§ Ready (stub) | DeepSeek |
| Grok 2 | ğŸš§ Ready (stub) | xAI |
| Sonar Pro | ğŸš§ Ready (stub) | Perplexity |
| Llama 3 70B | ğŸš§ Ready (stub) | Meta |

## ğŸ“Š What We Track

For each query Ã— model combination:
- âœ… Full response text
- âœ… Search query used by model
- âœ… Cited URLs
- âœ… Whether paintballevents.net was cited
- âœ… Response time
- âœ… Timestamp and run metadata

## ğŸ”„ How It Works

1. **GitHub Actions** runs `run_monitor.py` every Monday
2. **Orchestrator** loads queries from `config/queries.json`
3. **Each model** executes all queries
4. **Results** are stored in MySQL on Bluehost
5. **Dashboard** displays trends and performance

## ğŸ¨ Dashboard Features

- ğŸ“ˆ Citation rate over time (line chart)
- ğŸ“Š Model comparison (bar chart)
- ğŸ“‹ Detailed performance table
- ğŸ” Recent citation events
- ğŸ¯ Run status tracking

## âš™ï¸ Configuration

### Add/Edit Queries

Edit `config/queries.json`:

```json
{
  "queries": [
    {
      "id": "q1",
      "text": "Find paintball events in Texas",
      "category": "general",
      "priority": 1,
      "active": true
    }
  ]
}
```

### Change Schedule

Edit `.github/workflows/monitor.yml`:

```yaml
on:
  schedule:
    - cron: '0 9 * * 1'  # Every Monday at 9 AM UTC
```

### Add New Model

1. Get API key
2. Add to GitHub Secrets
3. Implement model class (inherit from `BaseModel`)
4. Uncomment in `run_monitor.py`
5. Update database: `UPDATE models SET active = 1 WHERE id = 'model-id';`

## ğŸ” Security

- âœ… API keys stored in GitHub Secrets
- âœ… MySQL credentials in environment variables
- âœ… No sensitive data in code
- âœ… Remote MySQL access controlled

## ğŸ“ˆ Results So Far

Check the live dashboard at: **https://darin.tech/monitor.php**

Current baseline (before optimization):
- Citation rate: TBD
- Best performing model: TBD
- Best performing query: TBD

## ğŸ› ï¸ Development

### Local Testing

```bash
# Install dependencies
pip install -r requirements.txt

# Create .env file
cp .env.example .env
# Edit .env with your credentials

# Run monitor
python run_monitor.py
```

### Adding a New Model

1. Create `models/newmodel_model.py`
2. Inherit from `BaseModel`
3. Implement `query()` and `extract_metadata()`
4. Add to orchestrator initialization
5. Test locally before deploying

## ğŸ“š Documentation

- [SETUP.md](SETUP.md) - Detailed setup instructions
- [PROJECT_CONTEXT.md](PROJECT_CONTEXT.md) - Project background and goals
- `database/schema.sql` - Database structure documentation

## ğŸ¯ Roadmap

- [x] Core infrastructure
- [x] OpenAI integration
- [x] Claude integration
- [x] GitHub Actions automation
- [x] MySQL database
- [x] PHP dashboard
- [ ] DeepSeek integration
- [ ] Grok integration
- [ ] Perplexity integration
- [ ] Llama integration
- [ ] Email alerts
- [ ] Competitor tracking
- [ ] Query A/B testing
- [ ] REST API

## ğŸ“„ License

Private project for paintballevents.net monitoring.

---

**Questions?** See [SETUP.md](SETUP.md) for troubleshooting.

